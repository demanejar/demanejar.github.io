<!DOCTYPE html><html lang="en-US" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta property="og:image" content="https://raw.githubusercontent.com/demanejar/image-collection/main/scrapy/Best-Free-Web-Crawler.jpg"> <script async src="https://www.googletagmanager.com/gtag/js?id=G-9TR0K3B846"></script> <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-8714452693053438" crossorigin="anonymous"></script> <script> window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-9TR0K3B846'); </script><meta name="generator" content="Jekyll v4.4.1" /><meta property="og:title" content="Crawl 1000 trang báo với Scrapy và MySQL" /><meta name="author" content="trannguyenhan" /><meta property="og:locale" content="en_US" /><meta name="description" content="Nếu với mỗi website lại viết 1 spider để phân tích thông tin thì sẽ rất mất thời gian, nhất là với các website tin tức, có hàng ngàn các website tin tức khác nhau và chúng còn mọc ra mỗi ngày." /><meta property="og:description" content="Nếu với mỗi website lại viết 1 spider để phân tích thông tin thì sẽ rất mất thời gian, nhất là với các website tin tức, có hàng ngàn các website tin tức khác nhau và chúng còn mọc ra mỗi ngày." /><link rel="canonical" href="https://demanejar.github.io/posts/crawl-1000-website-new-with-scrapy/" /><meta property="og:url" content="https://demanejar.github.io/posts/crawl-1000-website-new-with-scrapy/" /><meta property="og:site_name" content="De Manejar" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2023-03-01T20:52:00+07:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Crawl 1000 trang báo với Scrapy và MySQL" /><meta name="twitter:site" content="@DeManejar" /><meta name="twitter:creator" content="@trannguyenhan" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"trannguyenhan"},"dateModified":"2025-03-17T06:29:35+07:00","datePublished":"2023-03-01T20:52:00+07:00","description":"Nếu với mỗi website lại viết 1 spider để phân tích thông tin thì sẽ rất mất thời gian, nhất là với các website tin tức, có hàng ngàn các website tin tức khác nhau và chúng còn mọc ra mỗi ngày.","headline":"Crawl 1000 trang báo với Scrapy và MySQL","mainEntityOfPage":{"@type":"WebPage","@id":"https://demanejar.github.io/posts/crawl-1000-website-new-with-scrapy/"},"url":"https://demanejar.github.io/posts/crawl-1000-website-new-with-scrapy/"}</script><title>Crawl 1000 trang báo với Scrapy và MySQL | De Manejar</title><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon.png"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon-precomposed.png"><link rel="apple-touch-icon" sizes="57x57" href="/assets/img/favicons/apple-icon-57x57.png"><link rel="apple-touch-icon" sizes="60x60" href="/assets/img/favicons/apple-icon-60x60.png"><link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicons/apple-icon-72x72.png"><link rel="apple-touch-icon" sizes="76x76" href="/assets/img/favicons/apple-icon-76x76.png"><link rel="apple-touch-icon" sizes="114x114" href="/assets/img/favicons/apple-icon-114x114.png"><link rel="apple-touch-icon" sizes="120x120" href="/assets/img/favicons/apple-icon-120x120.png"><link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicons/apple-icon-144x144.png"><link rel="apple-touch-icon" sizes="152x152" href="/assets/img/favicons/apple-icon-152x152.png"><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-icon-180x180.png"><link rel="icon" type="image/png" sizes="192x192" href="/assets/img/favicons/android-icon-192x192.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/manifest.json"><meta name='msapplication-config' content='/assets/img/favicons/browserconfig.xml'><meta name="msapplication-TileColor" content="#ffffff"><meta name="msapplication-TileImage" content="/assets/img/favicons/ms-icon-144x144.png"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script defer src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script> /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */ MathJax = { tex: { inlineMath: [ /* start/end delimiter pairs for in-line math */ ['$','$'], ['\\(','\\)'] ], displayMath: [ /* start/end delimiter pairs for display math */ ['$$', '$$'], ['\\[', '\\]'] ] } }; </script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"> </script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id="></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', ''); }); </script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="https://i.pinimg.com/564x/9c/32/79/9c3279b5ac960533cbcb7e833ac4d947.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">De Manejar</a></div><div class="site-subtitle font-italic">Hello Bigdata !</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center"> <a href="https://github.com/demanejar" aria-label="github" class="order-3" target="_blank" rel="noopener"> <i class="fab fa-github-alt"></i> </a> <a href="https://twitter.com/DeManejar" aria-label="twitter" class="order-4" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['demanejar','gmail.com'].join('@')" aria-label="email" class="order-5" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" class="order-6" > <i class="fas fa-rss"></i> </a> <span class="icon-border order-2"></span> <span id="mode-toggle-wrapper" class="order-1"> <i class="mode-toggle fas fa-adjust"></i> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } var self = this; /* always follow the system prefers */ this.sysDarkPrefers.addListener(function() { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.updateMermaid(); }); } /* constructor() */ setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode == ModeToggle.DARK_MODE; } get isLightMode() { return this.mode == ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer) ) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } updateMermaid() { if (typeof mermaid !== "undefined") { let expectedTheme = (this.modeStatus === ModeToggle.DARK_MODE? "dark" : "default"); let config = { theme: expectedTheme }; /* re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */ $(".mermaid").each(function() { let svgCode = $(this).prev().children().html(); $(this).removeAttr("data-processed"); $(this).html(svgCode); }); mermaid.initialize(config); mermaid.init(undefined, ".mermaid"); } } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.updateMermaid(); } /* flipMode() */ } /* ModeToggle */ let toggle = new ModeToggle(); $(".mode-toggle").click(function() { toggle.flipMode(); }); </script> </span></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Posts </a> </span> <span>Crawl 1000 trang báo với Scrapy và MySQL</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>Crawl 1000 trang báo với Scrapy và MySQL</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> trannguyenhan </span> <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Wed, Mar 1, 2023, 8:52 PM +0700" prep="on" > Mar 1, 2023 <i class="unloaded">2023-03-01T20:52:00+07:00</i> </span></div><div> <span> <span class="timeago lastmod" data-toggle="tooltip" data-placement="bottom" title="Mon, Mar 17, 2025, 6:29 AM +0700" prefix="Updated " > Mar 17 <i class="unloaded">2025-03-17T06:29:35+07:00</i> </span> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="1979 words">10 min</span></div></div><div class="post-content"><p>Nếu với mỗi website lại viết 1 <code class="language-plaintext highlighter-rouge">spider</code> để phân tích thông tin thì sẽ rất mất thời gian, nhất là với các website tin tức, có hàng ngàn các website tin tức khác nhau và chúng còn mọc ra mỗi ngày.</p><p>Vậy bây giờ có một bài toán đặt ra là cần phân tích nội dung của 1000 website báo chí, và nhiệm vụ của chúng ta là phải lập lịch crawl 1000 website báo chí này hàng ngày. Việc lập lịch thì chúng ta có thể tạm giải quyết bằng <code class="language-plaintext highlighter-rouge">crontab</code>, vậy còn crawl 1000 website thì sao, không thể viết cả 1000 <code class="language-plaintext highlighter-rouge">spider</code> để parse từng website được! Vậy bài viết này chúng ta sẽ cùng tìm hiểu thêm cách sử dụng cơ sở dữ liệu để lưu cấu hình, cụ thể trong bài viết này sẽ sử dụng MySQL.</p><blockquote><p>Có thể có nhiều bạn thắc mắc là phân tích nội dung của 1000 website báo chí để làm gì? Bài toán này chủ yếu là để phân tích trend, từ khóa, sự kiện hot theo từng ngày, phân tích các nội dung, cho biết trang nào hay đăng lại bài của trang khác, các trang nào là các trang báo uy tín để gợi ý cho người dùng và còn ty tỷ thứ khác nữa.</p></blockquote><h2 id="tạo-project-và-định-nghĩa-item">Tạo project và định nghĩa Item</h2><p>Tạo một project Scrapy và một <code class="language-plaintext highlighter-rouge">Spider</code> news giống như bài viết <code class="language-plaintext highlighter-rouge">crawl-alonhadat</code>:</p><p><a href="https://demanejar.github.io/posts/crawl-housing-data-from-alonhadat/#t%E1%BA%A1o-m%E1%BB%99t-project-scrapy">Tạo project Crawl Alonhadat</a></p><p>Định nghĩa các thuộc tính cần lấy của một bài viết tin tức, bài viết này mình lấy 3 thuộc tính là URL, tiêu đề, nội dung và thời gian:</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre><td class="rouge-code"><pre><span class="c1"># Define here the models for your scraped items
#
# See documentation in:
# https://docs.scrapy.org/en/latest/topics/items.html
</span>
<span class="kn">import</span> <span class="n">scrapy</span>


<span class="k">class</span> <span class="nc">CrawlerItem</span><span class="p">(</span><span class="n">scrapy</span><span class="p">.</span><span class="n">Item</span><span class="p">):</span>
    <span class="c1"># define the fields for your item here like:
</span>    <span class="c1"># name = scrapy.Field()
</span>    <span class="n">url</span> <span class="o">=</span> <span class="n">scrapy</span><span class="p">.</span><span class="nc">Field</span><span class="p">()</span>
    <span class="n">title</span> <span class="o">=</span> <span class="n">scrapy</span><span class="p">.</span><span class="nc">Field</span><span class="p">()</span>
    <span class="n">content</span> <span class="o">=</span> <span class="n">scrapy</span><span class="p">.</span><span class="nc">Field</span><span class="p">()</span>
    <span class="n">date</span> <span class="o">=</span> <span class="n">scrapy</span><span class="p">.</span><span class="nc">Field</span><span class="p">()</span>
</pre></table></code></div></div><p>Các bạn muốn lấy thêm như là tác giả, hình ảnh, video, danh sách bài viết liên quan,… thì có thể định nghĩa thêm các trường cần lấy và viết thêm đoạn code tương ứng trong <code class="language-plaintext highlighter-rouge">Spider</code>.</p><h2 id="thiết-kế-cơ-sở-dữ-liệu">Thiết kế cơ sở dữ liệu</h2><p>Chúng ta lấy đại diện một website để phân tích, ở đây mình lấy kenh14. Vào trang chủ của kenh14 trước:</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://raw.githubusercontent.com/demanejar/image-collection/main/scrapy/kenh14_crawl1000news.png" alt="" /></p><p>Chúng ta thấy các trang báo mỗi trang đều có một trang chủ để chứa danh sách các bài viết, danh sách các bài viết này có thể là danh sách các bài viết nổi bật hoặc danh sách tất cả bài viết sắp xếp theo thứ tự mới nhất tùy vào từng trang. Vì thế nên việc lấy bài viết từ trang chủ có thể không đủ bài viết và tạp nham vì là kết hợp của rất nhiều nhãn. Vậy chúng ta sẽ đi lấy bài viết theo từng nhãn, tùy vào từng bài toán cần giải quyết có thể chắt lọc để lấy ra các dữ liệu cần thiết, ví dụ bài toán bạn muốn phân tích về trend hàng ngày thì crawl bài viết từ các nhãn giải trí, thế giới, đời sống, truyền thông chứ không cần thiết phải crawl các bài viết từ nhãn pháp luật và xe. Các nhãn của website được thể hiện chính là các thanh menu của từng website.</p><p>Project của chúng ta đang là lập lịch để crawl hàng ngày vì vậy không giống như project <a href="https://demanejar.github.io/posts/crawl-housing-data-from-alonhadat/">Crawl Alonhadat</a> phải next có khi tới 4000 trang để lấy dữ liệu đủ cho mô hình học máy hay học sâu thì với những project dạng này nếu là lập lịch chạy hàng ngày thì chỉ cần lấy bài viết mới nhất của ngày hôm nay hoặc cùng lắm chạy quá thêm 2-3 ngày nữa. Trong project này tại mỗi nhãn mình chỉ crawl bài viết trong <code class="language-plaintext highlighter-rouge">page đầu tiên</code> tìm thấy và lập lịch crawl lại <code class="language-plaintext highlighter-rouge">hàng giờ</code>. Nhiều bạn sợ sẽ bị trùng bài viết, nhưng đây không phải vấn đề quá lớn, chúng ta có thể lấy url của bài viết xong HASH ra để làm ID cập nhật vào cơ sở dữ liệu (Postgre, Elasticsearch,…) vì thế những bài viết trùng key sẽ được cập nhật mà không bị thêm thành nhiều bản ghi trong CSDL. Còn nếu crawl bị thiếu thì phải tính tới việc giảm tần suất từ 1h xuống còn 30p, 20p hoặc là tăng lượng bài viết mỗi lần crawl từ 1 trang lên 2-3 trang.</p><p>Mình thiết kế CSDL cho project này với 3 bảng:</p><ul><li>Bảng <code class="language-plaintext highlighter-rouge">websites</code>:</ul><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://raw.githubusercontent.com/demanejar/image-collection/main/scrapy/x_news_website.png" alt="" /></p><ul><li>Bảng <code class="language-plaintext highlighter-rouge">x_path_categories</code>:</ul><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://raw.githubusercontent.com/demanejar/image-collection/main/scrapy/x_news_x_path_categories.png" alt="" /></p><ul><li>Bảng <code class="language-plaintext highlighter-rouge">x_path_contents</code>:</ul><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://raw.githubusercontent.com/demanejar/image-collection/main/scrapy/x_news_x_path_contents.png" alt="" /></p><p>Với trường hợp mình xét tới trong project này là các trường hợp đơn gian nhất đó là các page danh sách bài viết của các nhãn của từng website có cấu trúc giống nhau và các page chi tiết bài viết của từng website cũng chỉ có 1 loại.</p><p>Ví dụ trang vietnamnet thì các trang vietnamnet.vn/vn/thoi-su, vietnamnet.vn/vn/kinh-doanh, vietnamnet.vn/vn/giai-tri, vietnamnet.vn/vn/the-gioi đều có cấu trúc website giống nhau nên bảng <code class="language-plaintext highlighter-rouge">x_path_categories</code> chỉ cần chỉ cần chứa ID của website và lưu thêm x_path thẻ bao bao bên ngoài danh sách bài viết.</p><p>Bảng <code class="language-plaintext highlighter-rouge">x_path_contents</code> thì khá dễ hiểu rồi, khi vào tớ một trang chi tiết thì nó là x_path để lấy ra từng thông tin chúng ta cần. Ở đây mình cũng xét một trường hợp đơn giản là một website chỉ có một loại trang chi tiết bài viết.</p><h2 id="kết-nối-cơ-sở-dữ-liệu">Kết nối cơ sở dữ liệu</h2><p>Cài đặt thư viện để kết nối tới CSDL cho python:</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">pip3</span> <span class="n">install</span> <span class="n">mysql</span><span class="o">-</span><span class="n">connector</span><span class="o">-</span><span class="n">python</span>
</pre></table></code></div></div><p>Có cơ sở dữ liệu rồi thì giờ phải viết thêm một đoạn Code để kết nối tới CSDL cho project Scrapy.</p><p>Tạo file <code class="language-plaintext highlighter-rouge">constants.py</code> để lưu lại thông tin về CSDL:</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre><span class="n">HOST</span> <span class="o">=</span> <span class="sh">"</span><span class="s">localhost</span><span class="sh">"</span>
<span class="n">USER</span> <span class="o">=</span> <span class="sh">"</span><span class="s">root</span><span class="sh">"</span>
<span class="n">PASSWORD</span> <span class="o">=</span> <span class="sh">"</span><span class="s">mysql12345</span><span class="sh">"</span>
<span class="n">DATABASE</span> <span class="o">=</span> <span class="sh">"</span><span class="s">x_news</span><span class="sh">"</span>
<span class="n">PORT</span> <span class="o">=</span> <span class="sh">"</span><span class="s">3306</span><span class="sh">"</span>
</pre></table></code></div></div><p>File <code class="language-plaintext highlighter-rouge">connector.py</code> sẽ lấy các thông tin tương ứng từ CSDL:</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="n">mysql.connector</span>
<span class="kn">from</span> <span class="n">crawler.spiders</span> <span class="kn">import</span> <span class="n">constants</span>

<span class="n">db</span> <span class="o">=</span> <span class="n">mysql</span><span class="p">.</span><span class="n">connector</span><span class="p">.</span><span class="nf">connect</span><span class="p">(</span>
    <span class="n">host</span><span class="o">=</span><span class="n">constants</span><span class="p">.</span><span class="n">HOST</span><span class="p">,</span>
    <span class="n">user</span><span class="o">=</span><span class="n">constants</span><span class="p">.</span><span class="n">USER</span><span class="p">,</span>
    <span class="n">password</span><span class="o">=</span><span class="n">constants</span><span class="p">.</span><span class="n">PASSWORD</span><span class="p">,</span>
    <span class="n">database</span><span class="o">=</span><span class="n">constants</span><span class="p">.</span><span class="n">DATABASE</span><span class="p">,</span>
    <span class="n">port</span><span class="o">=</span><span class="n">constants</span><span class="p">.</span><span class="n">PORT</span>
<span class="p">)</span>
<span class="n">cursor</span> <span class="o">=</span> <span class="n">db</span><span class="p">.</span><span class="nf">cursor</span><span class="p">()</span>

<span class="c1"># get all website in database
</span><span class="k">def</span> <span class="nf">get_all_websites</span><span class="p">():</span> 
    <span class="n">cursor</span><span class="p">.</span><span class="nf">execute</span><span class="p">(</span><span class="sh">"</span><span class="s">select * from websites</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">rows</span> <span class="o">=</span> <span class="n">cursor</span><span class="p">.</span><span class="nf">fetchall</span><span class="p">()</span>

    <span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">rows</span><span class="p">:</span> 
        <span class="n">result</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">result</span>

<span class="c1"># get all url categories of website
</span><span class="k">def</span> <span class="nf">get_categories</span><span class="p">(</span><span class="n">website_id</span><span class="p">):</span>
    <span class="n">cursor</span><span class="p">.</span><span class="nf">execute</span><span class="p">(</span><span class="sh">"</span><span class="s">select * from x_path_categories where website_id = </span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">website_id</span><span class="p">))</span>
    <span class="n">rows</span> <span class="o">=</span> <span class="n">cursor</span><span class="p">.</span><span class="nf">fetchall</span><span class="p">()</span>

    <span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">rows</span><span class="p">:</span> 
        <span class="n">result</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
    
    <span class="k">return</span> <span class="n">result</span>

<span class="c1"># get x_path of title, content of url website
</span><span class="k">def</span> <span class="nf">get_contents</span><span class="p">(</span><span class="n">website_id</span><span class="p">):</span>
    <span class="n">cursor</span><span class="p">.</span><span class="nf">execute</span><span class="p">(</span><span class="sh">"</span><span class="s">select * from x_path_contents where website_id = </span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">website_id</span><span class="p">))</span>
    <span class="n">rows</span> <span class="o">=</span> <span class="n">cursor</span><span class="p">.</span><span class="nf">fetchall</span><span class="p">()</span>

    <span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">rows</span><span class="p">:</span> 
        <span class="n">result</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span><span class="sh">"</span><span class="s">title</span><span class="sh">"</span><span class="p">:</span> <span class="n">row</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="n">row</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="sh">"</span><span class="s">date</span><span class="sh">"</span><span class="p">:</span> <span class="n">row</span><span class="p">[</span><span class="mi">4</span><span class="p">]})</span>

    <span class="k">return</span> <span class="n">result</span>
</pre></table></code></div></div><h2 id="viết-spider">Viết Spider</h2><p>Nếu mọi người theo dõi series này của mình thường xuyên thì sẽ thấy khi mình viết <code class="language-plaintext highlighter-rouge">Spider</code> thường có sử dụng 3 hàm: <code class="language-plaintext highlighter-rouge">start_requests</code> để chuẩn bị các đường link danh sách bài viết, hàm <code class="language-plaintext highlighter-rouge">parse_links</code> để lấy danh sách link chi tiết bài viết từ trang danh sách bài viết và hàm <code class="language-plaintext highlighter-rouge">parse</code> để lấy thông tin cần thiết từ trang chi tiết bài viết.</p><h3 id="hàm-start_requests">Hàm <code class="language-plaintext highlighter-rouge">start_requests</code></h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">start_requests</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
    <span class="n">list_websites</span> <span class="o">=</span> <span class="nf">get_all_websites</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">website</span> <span class="ow">in</span> <span class="n">list_websites</span><span class="p">:</span> 
        <span class="n">domain</span> <span class="o">=</span> <span class="n">website</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># get domain of website: https://vietnamnet.vn
</span>        <span class="n">categories</span> <span class="o">=</span> <span class="n">json</span><span class="p">.</span><span class="nf">loads</span><span class="p">(</span><span class="n">website</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span> <span class="c1"># get list category of website: /thoi-su, /chinh-tri
</span>        
        <span class="k">for</span> <span class="n">category</span> <span class="ow">in</span> <span class="n">categories</span><span class="p">:</span> 
            <span class="n">link</span> <span class="o">=</span> <span class="n">domain</span> <span class="o">+</span> <span class="n">category</span>
            <span class="k">yield</span> <span class="n">scrapy</span><span class="p">.</span><span class="nc">Request</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">link</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">parse_links</span><span class="p">,</span> <span class="n">meta</span><span class="o">=</span><span class="p">{</span><span class="sh">"</span><span class="s">website_id</span><span class="sh">"</span><span class="p">:</span> <span class="n">website</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="sh">"</span><span class="s">domain</span><span class="sh">"</span><span class="p">:</span> <span class="n">website</span><span class="p">[</span><span class="mi">1</span><span class="p">]})</span>
</pre></table></code></div></div><p>Hàm này tạo URL từng nhãn của các website từ dữ liệu trong CSDL (các dữ liệu trong CSDL các bạn xem thêm trong phần thiết kế CSDL ở bên trên), các link này chính là các link danh sách bài viết, ví dụ bản ghi đầu tiên có <code class="language-plaintext highlighter-rouge">domain = https://vietnamnet.vn</code> và <code class="language-plaintext highlighter-rouge">category = ["/vn/thoi-su/", "/vn/kinh-doanh/", "/vn/giai-tri/", "/vn/the-gioi/"]</code> thì sẽ đi từng nhãn một ghép lại thành một url hoàn chỉnh <code class="language-plaintext highlighter-rouge">https://vietnamnet.vn/vn/thoi-su/</code>, <code class="language-plaintext highlighter-rouge">https://vietnamnet.vn/vn/kinh-doanh/</code>, <code class="language-plaintext highlighter-rouge">https://vietnamnet.vn/vn/giai-tri/</code>, <code class="language-plaintext highlighter-rouge">https://vietnamnet.vn/vn/the-gioi/</code> các URL này chính là URL danh sách bài viết của từng nhãn, giờ gửi chúng xuống hàm <code class="language-plaintext highlighter-rouge">parse_link</code> để làm việc tiếp theo.</p><h3 id="hàm-parse_link">Hàm <code class="language-plaintext highlighter-rouge">parse_link</code></h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">parse_links</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="nf">set</span><span class="p">()</span>

    <span class="n">x_path_categories</span> <span class="o">=</span> <span class="nf">get_categories</span><span class="p">(</span><span class="n">response</span><span class="p">.</span><span class="n">meta</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="sh">"</span><span class="s">website_id</span><span class="sh">"</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">x_path_category</span> <span class="ow">in</span> <span class="n">x_path_categories</span><span class="p">:</span> 
        <span class="n">x_path</span> <span class="o">=</span> <span class="n">x_path_category</span> <span class="o">+</span> <span class="sh">"</span><span class="s">//a/@href</span><span class="sh">"</span> <span class="c1"># get all tag a, after get all attribute href contain link of post in website news
</span>        <span class="n">list_href</span> <span class="o">=</span> <span class="n">response</span><span class="p">.</span><span class="nf">xpath</span><span class="p">(</span><span class="n">x_path</span><span class="p">).</span><span class="nf">extract</span><span class="p">()</span>
        
        <span class="k">for</span> <span class="n">href</span> <span class="ow">in</span> <span class="n">list_href</span><span class="p">:</span> 
            <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">href</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">50</span> <span class="ow">and</span> <span class="p">(</span><span class="sh">"</span><span class="s">http</span><span class="sh">"</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">href</span><span class="p">):</span> <span class="c1"># link have less than 50 character maybe not is link of post
</span>                <span class="n">result</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="n">response</span><span class="p">.</span><span class="n">meta</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="sh">"</span><span class="s">domain</span><span class="sh">"</span><span class="p">)</span> <span class="o">+</span> <span class="n">href</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">result</span><span class="p">:</span> 
        <span class="k">yield</span> <span class="n">scrapy</span><span class="p">.</span><span class="nc">Request</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">item</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">parse</span><span class="p">,</span> <span class="n">meta</span><span class="o">=</span><span class="p">{</span><span class="sh">"</span><span class="s">website_id</span><span class="sh">"</span><span class="p">:</span> <span class="n">response</span><span class="p">.</span><span class="n">meta</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="sh">"</span><span class="s">website_id</span><span class="sh">"</span><span class="p">)})</span>
</pre></table></code></div></div><p>Ở hàm <code class="language-plaintext highlighter-rouge">start_request</code> chúng ta đã có gửi thêm tham số <code class="language-plaintext highlighter-rouge">"website_id": website[0]</code> xuống. <code class="language-plaintext highlighter-rouge">website_id</code> giúp chúng ta tìm được <code class="language-plaintext highlighter-rouge">x_path</code> của phần tử bao bên ngoài danh sách bài viết qua bảng <code class="language-plaintext highlighter-rouge">x_path_categories</code>. Sử dụng hàm <code class="language-plaintext highlighter-rouge">get_categories</code> đã viết trong phần kết nối CSDL để lấy ra <code class="language-plaintext highlighter-rouge">x_path</code> tương ứng, lấy ra danh sách URL của từng bài viết và gọi tới hàm <code class="language-plaintext highlighter-rouge">parse</code> cuối cùng.</p><p>Lưu ý là vẫn cần gửi <code class="language-plaintext highlighter-rouge">website_id</code> xuống hàm <code class="language-plaintext highlighter-rouge">parse</code> để có thể lấy các thông tin <code class="language-plaintext highlighter-rouge">x_path</code> trong bài viết được định nghĩa trong CSDL tại bảng <code class="language-plaintext highlighter-rouge">x_path_contents</code>.</p><h3 id="hàm-parse">Hàm <code class="language-plaintext highlighter-rouge">parse</code></h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>        
    <span class="n">posts</span> <span class="o">=</span> <span class="nf">get_contents</span><span class="p">(</span><span class="n">response</span><span class="p">.</span><span class="n">meta</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="sh">"</span><span class="s">website_id</span><span class="sh">"</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">post</span> <span class="ow">in</span> <span class="n">posts</span><span class="p">:</span> 
        <span class="n">content</span> <span class="o">=</span> <span class="n">response</span><span class="p">.</span><span class="nf">xpath</span><span class="p">(</span><span class="n">post</span><span class="p">[</span><span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">]</span> <span class="o">+</span> <span class="sh">""</span><span class="p">).</span><span class="nf">extract_first</span><span class="p">()</span>
        <span class="n">title</span> <span class="o">=</span> <span class="n">response</span><span class="p">.</span><span class="nf">xpath</span><span class="p">(</span><span class="n">post</span><span class="p">[</span><span class="sh">"</span><span class="s">title</span><span class="sh">"</span><span class="p">]</span> <span class="o">+</span> <span class="sh">"</span><span class="s">//text()</span><span class="sh">"</span><span class="p">).</span><span class="nf">extract_first</span><span class="p">()</span>
        <span class="n">date</span> <span class="o">=</span> <span class="n">response</span><span class="p">.</span><span class="nf">xpath</span><span class="p">(</span><span class="n">post</span><span class="p">[</span><span class="sh">"</span><span class="s">date</span><span class="sh">"</span><span class="p">]</span> <span class="o">+</span> <span class="sh">"</span><span class="s">//text()</span><span class="sh">"</span><span class="p">).</span><span class="nf">extract_first</span><span class="p">()</span>
        
        <span class="n">content</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">normalize</span><span class="p">(</span><span class="n">content</span><span class="p">)</span>
        <span class="n">title</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">normalize</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
        <span class="n">date</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">normalize</span><span class="p">(</span><span class="n">date</span><span class="p">)</span>
        
        <span class="n">crawlerItem</span> <span class="o">=</span> <span class="nc">CrawlerItem</span><span class="p">()</span>
        <span class="n">crawlerItem</span><span class="p">[</span><span class="sh">'</span><span class="s">content</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">content</span>
        <span class="n">crawlerItem</span><span class="p">[</span><span class="sh">'</span><span class="s">title</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">title</span>
        <span class="n">crawlerItem</span><span class="p">[</span><span class="sh">'</span><span class="s">date</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">date</span>
        <span class="n">crawlerItem</span><span class="p">[</span><span class="sh">'</span><span class="s">url</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">response</span><span class="p">.</span><span class="n">url</span>

        <span class="k">yield</span> <span class="n">crawlerItem</span>
</pre></table></code></div></div><p>Hàm này thì khá rõ ràng với mục đích của nó rồi, với từng <code class="language-plaintext highlighter-rouge">x_path</code> tương ứng trong CSDL lấy ra dữ liệu tương ứng và trả về <code class="language-plaintext highlighter-rouge">CrawlerItem</code>.</p><h2 id="chạy-và-lập-lịch-project">Chạy và lập lịch project</h2><p>Bài viết nằm trong series về Crawl nên mình cũng nói chủ yếu về crawl và cách lưu trữ để crawl mà ít nói về luồng của nó.</p><p>Các bạn có thể theo dõi đầy đủ project với luồng dữ liệu từ <code class="language-plaintext highlighter-rouge">lập lịch crawl -&gt; hàng đợi -&gt; Spark Streaming -&gt; Spark ML</code> tại <a href="https://github.com/trannguyenhan/X-news">https://github.com/trannguyenhan/X-news</a> (Source code này cũng từ khá lâu, một số các cái liên quan tới Kibana, ElastichSearch cũng không được cập nhật lên repo nên các bạn dùng tham khảo là chính thôi nha)</p><p>Chạy project với câu lệnh:</p><div class="language-bash highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>scrapy crawl news
</pre></table></code></div></div><p>Project này mình đang viết file pipeline với đầu ra dữ liệu được đẩy vào một hàng đợi <code class="language-plaintext highlighter-rouge">Kafka</code> để một bên khác nhận và xử lý dữ liệu phía sau, file <code class="language-plaintext highlighter-rouge">pipelines.py</code> được viết như dưới đây:</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
</pre><td class="rouge-code"><pre><span class="c1"># Define your item pipelines here
#
# Don't forget to add your pipeline to the ITEM_PIPELINES setting
# See: https://docs.scrapy.org/en/latest/topics/item-pipeline.html
</span>
<span class="c1"># useful for handling different item types with a single interface
</span><span class="kn">from</span> <span class="n">itemadapter</span> <span class="kn">import</span> <span class="n">ItemAdapter</span>
<span class="kn">from</span> <span class="n">kafka</span> <span class="kn">import</span> <span class="n">KafkaProducer</span>
<span class="kn">import</span> <span class="n">json</span>

<span class="k">class</span> <span class="nc">CrawlerPipeline</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">open_spider</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">spider</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">producer</span> <span class="o">=</span> <span class="nc">KafkaProducer</span><span class="p">(</span><span class="n">bootstrap_servers</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">localhost:9092</span><span class="sh">'</span><span class="p">],</span> \
            <span class="n">value_serializer</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">json</span><span class="p">.</span><span class="nf">dumps</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">ensure_ascii</span><span class="o">=</span><span class="bp">False</span><span class="p">).</span><span class="nf">encode</span><span class="p">(</span><span class="sh">'</span><span class="s">utf-8</span><span class="sh">'</span><span class="p">))</span>
        <span class="n">self</span><span class="p">.</span><span class="n">topic</span> <span class="o">=</span> <span class="sh">"</span><span class="s">x_news_1</span><span class="sh">"</span>

    <span class="k">def</span> <span class="nf">process_item</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">item</span><span class="p">,</span> <span class="n">spider</span><span class="p">):</span>
        <span class="n">line</span> <span class="o">=</span> <span class="nc">ItemAdapter</span><span class="p">(</span><span class="n">item</span><span class="p">).</span><span class="nf">asdict</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">producer</span><span class="p">.</span><span class="nf">send</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">topic</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">line</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">item</span>

</pre></table></code></div></div><p>Toàn bộ project Crawl này các bạn có thể tham khảo tại link GITHUB: <a href="https://github.com/demanejar/crawler-1000news">https://github.com/demanejar/crawler-1000news</a>.</p><p>Để lập lịch cho con <code class="language-plaintext highlighter-rouge">Spider</code> chạy hàng ngày có thể sử dụng <code class="language-plaintext highlighter-rouge">crontab</code>, cái này hoạt động khá đơn giản, copy lệnh chạy vào file nó quét qua là được. Xem thêm về <code class="language-plaintext highlighter-rouge">cron</code> tại <a href="https://viblo.asia/p/task-schedule-trong-laravel-naQZRkOqlvx#_crontab-0">https://viblo.asia/p/task-schedule-trong-laravel-naQZRkOqlvx#_crontab-0</a>.</p><p>Vì website không có mục bình luận dưới bài viết nên mọi người thảo luận và góp ý cho mình tại GITHUB DISCUSSION này nha: <a href="https://github.com/orgs/demanejar/discussions/1">https://github.com/orgs/demanejar/discussions/1</a>.</p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/crawler/'>Crawler</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/crawler/" class="post-tag no-text-decoration" >Crawler</a> <a href="/tags/scrapy/" class="post-tag no-text-decoration" >Scrapy</a> <a href="/tags/alonhadat/" class="post-tag no-text-decoration" >alonhadat</a> <a href="/tags/mysql/" class="post-tag no-text-decoration" >MySQL</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Crawl 1000 trang báo với Scrapy và MySQL - De Manejar&url=https://demanejar.github.io/posts/crawl-1000-website-new-with-scrapy/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Crawl 1000 trang báo với Scrapy và MySQL - De Manejar&u=https://demanejar.github.io/posts/crawl-1000-website-new-with-scrapy/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=Crawl 1000 trang báo với Scrapy và MySQL - De Manejar&url=https://demanejar.github.io/posts/crawl-1000-website-new-with-scrapy/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink()" data-toggle="tooltip" data-placement="top" title="Copy link"></i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/k8s/">Tìm hiểu tổng quan k8s</a><li><a href="/posts/add-proxy-to-scrapy-project/">Cấu hình proxy cho project Scrapy</a><li><a href="/posts/crawl-1000-website-new-with-scrapy/">Crawl 1000 trang báo với Scrapy và MySQL</a><li><a href="/posts/php-scraper/">PHP Scraper</a><li><a href="/posts/scrapy-shell/">Giới thiệu Scrapy Shell</a></ul></div><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/bigdata/">Bigdata</a> <a class="post-tag" href="/tags/spark/">Spark</a> <a class="post-tag" href="/tags/crawler/">Crawler</a> <a class="post-tag" href="/tags/hdfs/">HDFS</a> <a class="post-tag" href="/tags/scrapy/">Scrapy</a> <a class="post-tag" href="/tags/hadoop/">Hadoop</a> <a class="post-tag" href="/tags/apache-hadoop/">Apache Hadoop</a> <a class="post-tag" href="/tags/ubuntu/">Ubuntu</a> <a class="post-tag" href="/tags/spark-sql/">Spark SQL</a> <a class="post-tag" href="/tags/alonhadat/">alonhadat</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/add-proxy-to-scrapy-project/"><div class="card-body"> <span class="timeago small" > Feb 15, 2023 <i class="unloaded">2023-02-15T20:52:00+07:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Cấu hình proxy cho project Scrapy</h3><div class="text-muted small"><p> Proxy chắc là khái niệm đã không còn xa lạ gì với tất cả mọi người. Với người làm về crawl dữ liệu thì proxy như vật bất ly thân. Trong bài viết này, mình sẽ hướng dẫn cách cấu hình proxy cho proje...</p></div></div></a></div><div class="card"> <a href="/posts/crawl-housing-data-from-alonhadat/"><div class="card-body"> <span class="timeago small" > Jan 24, 2023 <i class="unloaded">2023-01-24T20:52:00+07:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Crawl dữ liệu nhà đất từ alonhadat với Scrapy</h3><div class="text-muted small"><p> Trong bài viết này mình sẽ giới thiệu chi tiết về cách tạo một project với Scrapy và sử dụng để phân tích lấy dữ liệu nhà đất từ trang alonhadat. Nếu máy bạn chưa có Scrapy thì có thể cài đặt bằng...</p></div></div></a></div><div class="card"> <a href="/posts/scrapy-shell/"><div class="card-body"> <span class="timeago small" > Apr 1, 2023 <i class="unloaded">2023-04-01T20:52:00+07:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Giới thiệu Scrapy Shell</h3><div class="text-muted small"><p> Mỗi lần viết 1 spider chúng ta phải viết nhiều các đoạn css selector, xpath để phân tích thông tin mà nhiều lúc không biết nó đúng hay sai. Mỗi lần như vậy thì lại phải chạy project rồi in ra thông...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/add-proxy-to-scrapy-project/" class="btn btn-outline-primary" prompt="Older"><p>Cấu hình proxy cho project Scrapy</p></a> <a href="/posts/php-scraper/" class="btn btn-outline-primary" prompt="Newer"><p>PHP Scraper</p></a></div></div></div></div><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script> <script type="text/javascript"> const imgs = document.querySelectorAll('.post-content img'); const observer = lozad(imgs); observer.observe(); </script><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2025 <a href="https://twitter.com/DeManejar">demanejar</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div></div><script type="text/javascript"> var links = document.links; for (var i = 0, linksLength = links.length; i < linksLength; i++) { if (links[i].hostname != window.location.hostname) { links[i].target = '_blank'; } } </script></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/bigdata/">Bigdata</a> <a class="post-tag" href="/tags/spark/">Spark</a> <a class="post-tag" href="/tags/crawler/">Crawler</a> <a class="post-tag" href="/tags/hdfs/">HDFS</a> <a class="post-tag" href="/tags/scrapy/">Scrapy</a> <a class="post-tag" href="/tags/hadoop/">Hadoop</a> <a class="post-tag" href="/tags/apache-hadoop/">Apache Hadoop</a> <a class="post-tag" href="/tags/ubuntu/">Ubuntu</a> <a class="post-tag" href="/tags/spark-sql/">Spark SQL</a> <a class="post-tag" href="/tags/alonhadat/">alonhadat</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><script src="https://cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js"></script> <script> $(function() { let initTheme = "default"; if ($("html[mode=dark]").length > 0 || ($("html[mode]").length == 0 && window.matchMedia("(prefers-color-scheme: dark)").matches ) ) { initTheme = "dark"; } let mermaidConf = { theme: initTheme /* <default|dark|forest|neutral> */ }; /* Markdown converts to HTML */ $("pre").has("code.language-mermaid").each(function() { let svgCode = $(this).children().html(); $(this).addClass("unloaded"); $(this).after(`<div class=\"mermaid\">${svgCode}</div>`); }); mermaid.initialize(mermaidConf); }); </script><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://demanejar.github.io{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script>
